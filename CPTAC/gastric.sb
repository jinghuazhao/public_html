#!/usr/bin/bash

#SBATCH --job-name gastric
#SBATCH --account PETERS-SL3-CPU
#SBATCH --partition cclake-himem
#SBATCH --mem=28800
#SBATCH --array=31
#SBATCH --time=10:00:00
#SBATCH --mail-type=NONE
#SBATCH --output=/rds/project/jmmh2/rds-jmmh2-public_databases/CPTAC/TEMP/_gastric_%A_%a.o
#SBATCH --error=/rds/project/jmmh2/rds-jmmh2-public_databases/CPTAC/TEMP/_gastric_%A_%a.e

. /etc/profile.d/modules.sh
module purge
module load rhel7/default-ccl
module load ceuadmin/sra-tools/3.0.8
module load perl-5.20.0-gcc-5.4.0-4npvg5p

TMPDIR=~/rds/rds-jmmh2-public_databases/CPTAC/TEMP
destdir=~/rds/rds-jmmh2-public_databases/CPTAC/TEMP/gastric_Korea_2019/SRA_PRJNA505380

accession=$(awk -v n=${SLURM_ARRAY_TASK_ID} 'NR==n' gastric.list)
cd ${TMPDIR}
echo -e "Changed directory from $SLURM_SUBMIT_DIR to ${TMPDIR}.\n"
prefetch --transport http --max-size u --progress ${accession}
if [ -d ${accession} ]; then
  fasterq-dump ${accession} -O ${destdir}
fi
echo -e "JobID: $SLURM_JOB_ID\n============="
echo "Time: `date`"
echo "Running on master node: `hostname`"
echo "Current directory: `pwd`"
vdb-dump ${accession} --info
if [ "$SLURM_JOB_NODELIST" ]; then
        #! Create a machine file:
        export NODEFILE=`generate_pbs_nodefile $SLURM_JOB_NODELIST`
        cat $NODEFILE | uniq > machine.file-$SLURM_ARRAY_TASK_ID
        echo -e "\nNodes allocated:\n================"
        cat machine.file-$SLURM_ARRAY_TASK_ID | sed -e 's/\..*$//g'
fi
echo -e "\nExecuting command:\n==================\n$CMD\n"
cd -

# tidy-up: cd $TMPDIR; ll -rt | grep jhz22 | awk '{print "rm " $NF}' | bash
